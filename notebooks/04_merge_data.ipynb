{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc318832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from shared import *\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(workspace='./data/', output='merged/', download=True, target='archive', merge='fraud'):\n",
    "    if download:\n",
    "        # get all the data from S3\n",
    "        download_bucket_folder(target)\n",
    "        download_bucket_folder(merge)\n",
    "\n",
    "    # load the target data\n",
    "    input_dir = workspace + target\n",
    "    files = [os.path.join(input_dir, f) for f in os.listdir(input_dir)]\n",
    "    \n",
    "    target_df = load_transactions(files)\n",
    "\n",
    "    target_df = target_df.sort_values('TRANSACTION_ID')\n",
    "    target_df.reset_index(drop=True, inplace=True)\n",
    "    target_df = target_df.drop_duplicates()\n",
    "\n",
    "    # load the \"to be merge\" data\n",
    "    input_dir = workspace + merge\n",
    "    files = [os.path.join(input_dir, f) for f in os.listdir(input_dir)]\n",
    "    \n",
    "    merge_df = load_transactions(files)\n",
    "\n",
    "    merge_df = merge_df.sort_values('TRANSACTION_ID')\n",
    "    merge_df.reset_index(drop=True, inplace=True)\n",
    "    merge_df = merge_df.drop_duplicates()\n",
    "\n",
    "    # merge the prediction data\n",
    "    for index, row in merge_df.iterrows():\n",
    "        idx = target_df.loc[target_df['TRANSACTION_ID'] == row['TRANSACTION_ID']]\n",
    "        if len(idx) > 0:\n",
    "            target_df.loc[idx.index, ['TX_FRAUD_SCENARIO']] = row['TX_FRAUD_SCENARIO']\n",
    "            target_df.loc[idx.index, ['TX_FRAUD_PREDICTION']] = 1\n",
    "            target_df.loc[idx.index, ['TX_FRAUD_PROBABILITY']] = 1.0\n",
    "\n",
    "    # sort the result chronological\n",
    "    target_df = target_df.sort_values('TX_DATETIME')\n",
    "    target_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # add columns that makes sorting and grouping easier\n",
    "    start_date = target_df['TX_DATETIME'].min().strftime(\"%Y-%m-%d\")\n",
    "    sd = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "    target_df['TX_TIME_SECONDS'] = pd.to_numeric(target_df['TX_DATETIME']) / 1000000000\n",
    "    target_df['TX_TIME_SECONDS'] = target_df['TX_TIME_SECONDS'].astype(int)\n",
    "\n",
    "    target_df['TX_TIME_DAYS'] = tx_df['TX_DATETIME'] - sd\n",
    "    target_df['TX_TIME_DAYS'] = tx_df['TX_TIME_DAYS'].apply(lambda x: x.days)\n",
    "\n",
    "    # save the merged data, grouped by day\n",
    "    save_transactions_day(target_df, start_date, output_dir=workspace + output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb07a80f420f2a3c6f994f3d4ceda3af88f46f0442cb787adf66c08d5cc259f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
