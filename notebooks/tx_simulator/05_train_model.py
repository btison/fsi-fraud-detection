#!/usr/bin/env python
# coding: utf-8
import os
import sys  # debug remove later
import time
import datetime
import pandas as pd
import cloudpickle as cp

from sklearn.tree import DecisionTreeClassifier

from shared import load_transactions
from model.training import get_train_test_set


DIR_INPUT = os.getenv('source_location', './data/simulated/training')
DIR_OUTPUT = os.getenv('target_location', './data/model/')


output_feature = "TX_FRAUD"

input_features = ['TX_AMOUNT', 'TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',
                  'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',
                  'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',
                  'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',
                  'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',
                  'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',
                  'TERMINAL_ID_RISK_30DAY_WINDOW']


# load a singel file or all files in the directory
files = []
if DIR_INPUT.endswith('.csv'):
    files = [DIR_INPUT]
else:
    # load all training files generated by the simulator
    files = [os.path.join(DIR_INPUT, f) for f in os.listdir(DIR_INPUT)]

# load training data
tx_df = load_transactions(files)

# date range
start_date_training = tx_df['TX_DATETIME'].min()
start_date = start_date_training.strftime("%Y-%m-%d")

# split data into training and test data
(train_df, test_df) = get_train_test_set(
    tx_df, start_date_training, delta_train=7, delta_delay=7, delta_test=7)


# We first create a decision tree object. We will limit its depth to 2 for interpretability,
# and set the random state to zero for reproducibility
classifier = DecisionTreeClassifier(max_depth=2, random_state=0)


# fit the data
classifier.fit(train_df[input_features], train_df[output_feature])

# test the classifier
fraud_df = test_df.loc[test_df['TX_FRAUD'] == 1]
fraud_df['TX_FRAUD_PREDICTION'] = classifier.predict(fraud_df[input_features])
fraud_df['TX_FRAUD_PROBABILITY'] = classifier.predict_proba(
    fraud_df[input_features])[:, 1]

# debug

if not os.path.exists(DIR_OUTPUT):
    os.makedirs(DIR_OUTPUT)

ts = int(datetime.datetime.timestamp(datetime.datetime.now()) * 100000)
#fraud_df.to_csv(DIR_OUTPUT+f"test_{ts}.csv", index=False)

# save the classifier
cp.dump(classifier, open(DIR_OUTPUT+f"model_{ts}.pkl", "wb"))
cp.dump(classifier, open(DIR_OUTPUT+f"model_latest.pkl", "wb"))